{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 녹음 -> blob에 저장 -> 로드 -> STT -> blob에 저장 -> 로드 -> SUM -> 결과출력/blob저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실시간 녹음 시작... (Enter 또는 CTRL+C를 눌러 종료)\n",
      "녹음 종료\n",
      "WAV 파일 저장 완료: ./live_audio_20250203_205024.wav\n",
      "오디오 파일 업로드 완료: live_audio_20250203_205024.wav\n",
      "음성을 텍스트로 변환 중...\n",
      "STT 변환 결과: 담론은 쓸개주머니라고도 하는데 담즙을 저장하는 역할을 하는 기관이에요. 이 담즙이라는 건 지방을 소환하는 데 도움을 주는 소화액인데 담낭을 제거한다고 해서 소화가 안 되는 건 아니에요. 담즙은 담낭에서 만드는 게 아니고 관에서 만드는 거기 때문에 담낭에 없어도 담즙은 계속 만들어 내거든요.\n",
      "STT 변환된 텍스트 업로드 완료: live_audio_20250203_205024.txt\n",
      "📤 요약된 텍스트 업로드 완료: live_audio_20250203_205024_summary.txt\n",
      "\n",
      "📌 요약된 내용:\n",
      "- 용어 설명: 담낭은 쓸개주머니라고도 하며, 담즙을 저장하는 기관입니다.\n",
      "- 소화 기능: 담즙은 지방 소화에 도움을 주는 소화액입니다.\n",
      "- 담즙 생성: 담즙은 담낭이 아닌 관에서 생성되므로, 담낭이 없어도 계속 생성됩니다.\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import pyaudio\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from datetime import datetime\n",
    "import io\n",
    "import keyboard\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# 🔹 .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 🔹 환경 변수에서 Azure Storage 및 OpenAI 설정 가져오기\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION = \"2024-08-01-preview\"\n",
    "\n",
    "# 🔹 컨테이너 설정\n",
    "BLOB_AUDIO_CONTAINER = \"audio-files\"\n",
    "STT_RESULTS_CONTAINER = \"stt-results\"\n",
    "SUMMARIZED_RESULTS_CONTAINER = \"sum-results\"\n",
    "\n",
    "# 🔹 Azure Storage 클라이언트 생성\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "\n",
    "# 🔹 Azure OpenAI 클라이언트 생성\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "# 🔹 녹음 설정\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000  # 16kHz (Azure STT 최적화)\n",
    "CHUNK = 1024\n",
    "\n",
    "def create_container_if_not_exists(container_name):\n",
    "    \"\"\"Azure Blob Storage 컨테이너가 없으면 생성\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    if not container_client.exists():\n",
    "        container_client.create_container()\n",
    "\n",
    "create_container_if_not_exists(BLOB_AUDIO_CONTAINER)\n",
    "create_container_if_not_exists(STT_RESULTS_CONTAINER)\n",
    "create_container_if_not_exists(SUMMARIZED_RESULTS_CONTAINER)\n",
    "\n",
    "def record_and_upload():\n",
    "    \"\"\"마이크로 음성을 녹음한 후, WAV 파일로 변환하여 Azure Blob Storage에 저장\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    blob_name = f\"live_audio_{timestamp}.wav\"\n",
    "    local_audio_path = f\"./{blob_name}\"\n",
    "    blob_client = blob_service_client.get_blob_client(container=BLOB_AUDIO_CONTAINER, blob=blob_name)\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"실시간 녹음 시작... (Enter 또는 CTRL+C를 눌러 종료)\")\n",
    "    frames = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "            if keyboard.is_pressed(\"enter\"):\n",
    "                print(\"녹음 종료\")\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"녹음 종료 (CTRL+C 입력 감지됨)\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # WAV 파일로 저장\n",
    "    with wave.open(local_audio_path, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(f\"WAV 파일 저장 완료: {local_audio_path}\")\n",
    "\n",
    "    # Azure Blob Storage에 업로드\n",
    "    with open(local_audio_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "    print(f\"오디오 파일 업로드 완료: {blob_name}\")\n",
    "    return blob_name\n",
    "\n",
    "def transcribe_audio(blob_name):\n",
    "    \"\"\"Azure STT API를 사용하여 Blob Storage에서 직접 변환\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    blob_client = blob_service_client.get_blob_client(container=BLOB_AUDIO_CONTAINER, blob=blob_name)\n",
    "    blob_data = blob_client.download_blob().readall()\n",
    "\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_region = os.getenv(\"SPEECH_REGION\")\n",
    "\n",
    "    if not speech_key or not speech_region:\n",
    "        raise ValueError(\"환경 변수 SPEECH_API_KEY 또는 SPEECH_REGION이 설정되지 않았습니다.\")\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.speech_recognition_language = \"ko-KR\"\n",
    "\n",
    "    stream_reader = io.BytesIO(blob_data)\n",
    "    audio_input_stream = speechsdk.audio.AudioConfig(filename=blob_name)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input_stream)\n",
    "\n",
    "    print(\"음성을 텍스트로 변환 중...\")\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(f\"STT 변환 결과: {result.text}\")\n",
    "        return result.text\n",
    "    else:\n",
    "        print(\"음성 인식 실패\")\n",
    "        return None\n",
    "\n",
    "def upload_stt_result_to_blob(text_data, audio_blob_name):\n",
    "    \"\"\"STT 변환된 텍스트를 Blob Storage에 저장\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    text_blob_name = audio_blob_name.replace(\".wav\", \".txt\")\n",
    "    blob_client = blob_service_client.get_blob_client(container=STT_RESULTS_CONTAINER, blob=text_blob_name)\n",
    "    blob_client.upload_blob(text_data, overwrite=True)\n",
    "    print(f\"STT 변환된 텍스트 업로드 완료: {text_blob_name}\")\n",
    "    return text_blob_name\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Azure OpenAI를 사용하여 STT 결과를 요약\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    당신은 환자와 의사의 대화를 분석하는 AI입니다.  \n",
    "    아래의 대화 내용을 기반으로 핵심 정보는 유지하면서도 짧고 간결한 요약을 생성하세요.  \n",
    "    ❗ 줄글이 아닌, `진단:`, `수술 계획:`, `부작용:` 등의 키워드 형식을 유지하세요.  \n",
    "\n",
    "    입력 데이터:\n",
    "    \\\"\\\"\\\" {text} \\\"\\\"\\\"  \n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant specialized in summarizing medical conversations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    return summary\n",
    "\n",
    "def upload_summary_to_blob(summary_text, original_filename):\n",
    "    \"\"\"요약된 텍스트를 Blob Storage(sum_results 컨테이너)에 저장\"\"\"\n",
    "    summary_blob_name = original_filename.replace(\".txt\", \"_summary.txt\")\n",
    "    blob_client = blob_service_client.get_blob_client(container=SUMMARIZED_RESULTS_CONTAINER, blob=summary_blob_name)\n",
    "    blob_client.upload_blob(summary_text, overwrite=True)\n",
    "    print(f\"📤 요약된 텍스트 업로드 완료: {summary_blob_name}\")\n",
    "\n",
    "# 🔹 실행 흐름\n",
    "audio_filename = record_and_upload()\n",
    "stt_text = transcribe_audio(audio_filename)\n",
    "\n",
    "if stt_text:\n",
    "    stt_filename = upload_stt_result_to_blob(stt_text, audio_filename)\n",
    "    summarized_text = summarize_text(stt_text)\n",
    "    upload_summary_to_blob(summarized_text, stt_filename)\n",
    "\n",
    "    print(\"\\n📌 요약된 내용:\")\n",
    "    print(summarized_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 저장 없이 시도 -> 오 된듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음 시작... (Enter 또는 CTRL+C를 눌러 종료)\n",
      "녹음 종료\n",
      "Blob Storage에 업로드 중: live_audio_20250204_095618.wav\n",
      "음성을 텍스트로 변환 중...\n",
      "STT 변환 결과: 그래서 녹음을 뭐 어쩌고저쩌고 이렇게 한 다음에.\n",
      "STT 변환된 텍스트 업로드 완료: live_audio_20250204_095618.txt\n",
      "요약된 텍스트 업로드 완료: live_audio_20250204_095618_summary.txt\n",
      "\n",
      "요약된 내용:\n",
      "죄송하지만, 제공된 정보를 기반으로 요약을 생성할 수 없습니다. 입력 데이터에 대화 내용이 포함되어 있지 않기 때문입니다. 올바른 대화 내용을 제공해 주시면, 처리해 드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import pyaudio\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from datetime import datetime\n",
    "import io\n",
    "import keyboard\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# 🔹 .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 🔹 환경 변수에서 Azure Storage 및 OpenAI 설정 가져오기\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION = \"2024-08-01-preview\"\n",
    "\n",
    "# 🔹 컨테이너 설정\n",
    "BLOB_AUDIO_CONTAINER = \"audio-files\"\n",
    "STT_RESULTS_CONTAINER = \"stt-results\"\n",
    "SUMMARIZED_RESULTS_CONTAINER = \"sum-results\"\n",
    "\n",
    "# 🔹 Azure Storage 클라이언트 생성\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "\n",
    "# 🔹 Azure OpenAI 클라이언트 생성\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "# 🔹 녹음 설정\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000  # 16kHz (Azure STT 최적화)\n",
    "CHUNK = 1024\n",
    "\n",
    "def create_container_if_not_exists(container_name):\n",
    "    \"\"\"Azure Blob Storage 컨테이너가 없으면 생성\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    if not container_client.exists():\n",
    "        container_client.create_container()\n",
    "\n",
    "create_container_if_not_exists(BLOB_AUDIO_CONTAINER)\n",
    "create_container_if_not_exists(STT_RESULTS_CONTAINER)\n",
    "create_container_if_not_exists(SUMMARIZED_RESULTS_CONTAINER)\n",
    "\n",
    "def record_and_upload():\n",
    "    \"\"\"마이크로 음성을 녹음한 후, Azure Blob Storage에 직접 업로드\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    blob_name = f\"live_audio_{timestamp}.wav\"\n",
    "    blob_client = blob_service_client.get_blob_client(container=BLOB_AUDIO_CONTAINER, blob=blob_name)\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"녹음 시작... (Enter 또는 CTRL+C를 눌러 종료)\")\n",
    "    frames = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "            if keyboard.is_pressed(\"enter\"):\n",
    "                print(\"녹음 종료\")\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"녹음 종료\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # **메모리에 WAV 파일 변환 (로컬 저장 X)**\n",
    "    wav_data = io.BytesIO()\n",
    "    with wave.open(wav_data, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)  # **16비트 PCM**\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(f\"Blob Storage에 업로드 중: {blob_name}\")\n",
    "    blob_client.upload_blob(wav_data.getvalue(), overwrite=True)\n",
    "\n",
    "    return blob_name\n",
    "\n",
    "\n",
    "class BinaryAudioStreamReader(speechsdk.audio.PullAudioInputStreamCallback):\n",
    "    \"\"\"Azure Speech SDK에서 사용할 수 있도록 Binary Audio Stream Reader 정의\"\"\"\n",
    "    def __init__(self, audio_data):\n",
    "        super().__init__()\n",
    "        self._audio_data = io.BytesIO(audio_data)\n",
    "\n",
    "    def read(self, buffer):\n",
    "        \"\"\"Azure Speech SDK에서 호출하는 read 메서드\"\"\"\n",
    "        size = len(buffer)\n",
    "        data = self._audio_data.read(size)\n",
    "        buffer[:len(data)] = data  # 메모리 버퍼에 데이터를 채움\n",
    "        return len(data)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"스트림 종료\"\"\"\n",
    "        self._audio_data.close()\n",
    "\n",
    "\n",
    "def transcribe_audio(blob_name):\n",
    "    \"\"\"Azure STT API를 사용하여 Blob Storage에서 직접 변환\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    blob_client = blob_service_client.get_blob_client(container=BLOB_AUDIO_CONTAINER, blob=blob_name)\n",
    "    blob_data = blob_client.download_blob().readall()  # **Blob Storage에서 WAV 파일 데이터 가져오기**\n",
    "\n",
    "    speech_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "    speech_region = os.getenv(\"SPEECH_REGION\")\n",
    "\n",
    "    if not speech_key or not speech_region:\n",
    "        raise ValueError(\"환경 변수 SPEECH_API_KEY 또는 SPEECH_REGION이 설정되지 않았습니다.\")\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.speech_recognition_language = \"ko-KR\"\n",
    "\n",
    "    # ** WAV 데이터를 올바르게 변환하여 PullAudioInputStream 생성**\n",
    "    stream_reader = BinaryAudioStreamReader(blob_data)\n",
    "    audio_input_stream = speechsdk.audio.PullAudioInputStream(stream_reader)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=audio_input_stream)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print(\"음성을 텍스트로 변환 중...\")\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(f\"STT 변환 결과: {result.text}\")\n",
    "        return result.text\n",
    "    else:\n",
    "        print(\"음성 인식 실패\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def upload_stt_result_to_blob(text_data, audio_blob_name):\n",
    "    \"\"\"STT 변환된 텍스트를 Blob Storage에 저장\"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "    text_blob_name = audio_blob_name.replace(\".wav\", \".txt\")\n",
    "    blob_client = blob_service_client.get_blob_client(container=STT_RESULTS_CONTAINER, blob=text_blob_name)\n",
    "    blob_client.upload_blob(text_data, overwrite=True)\n",
    "    print(f\"STT 변환된 텍스트 업로드 완료: {text_blob_name}\")\n",
    "    return text_blob_name\n",
    "\n",
    "def summarize_text(text):\n",
    "    \"\"\"Azure OpenAI를 사용하여 STT 결과를 요약\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    당신은 환자와 의사의 대화를 분석하는 AI입니다.  \n",
    "    아래의 대화 내용을 기반으로 **핵심 정보는 유지하면서도 짧고 간결한 요약**을 생성하세요.  \n",
    "\n",
    "    ❗ 단, 언급한 의학적 내용이 삭제되지 않도록 하며, 설명이 필요하면 간결한 문장으로 추가하세요.  \n",
    "    ❗ 정보가 너무 축약되지 않도록 하며, **한 항목당 최소 2개 이상의 핵심 내용을 유지하세요.**  \n",
    "    ❗ 줄글이 아닌, `진단:`, `수술/치료 계획:` 등의 키워드 형식을 유지하세요.  \n",
    "    ❗ **부작용 및 위험** 항목에서는 주요 합병증(담관 손상, 담즙 누출, 출혈 등)에 대해 개별적으로 설명하세요. 이 부분만 줄글이고 나머지는 키워드 형식 유지.\n",
    "    ❗ 환자가 우려하는 부분에 대해서는 반드시 요약하세요.\n",
    "\n",
    "    입력 데이터:\n",
    "    \\\"\\\"\\\" {text} \\\"\\\"\\\"  \n",
    "\n",
    "    ### **출력 형식 (각 항목을 간결하지만 핵심 내용을 유지하면서 요약)**  \n",
    "    - **진단:** [질병명]  \n",
    "    - 예: 급성 담낭염  \n",
    "\n",
    "    - **수술/치료 계획:** [필요한 절차, 치료 선택 이유, 치료 효과, 수술과 관련된 주요 문제점]  \n",
    "\n",
    "    - **부작용 및 위험:** [예상 가능한 부작용, 합병증 발생 가능성, 합병증 발생 시 대처법]  \n",
    "    - **[합병증명]:** [합병증 설명] \n",
    "    - **[합병증명]:** [합병증 설명] \n",
    "\n",
    "    - **주의사항:** [수술 전후 환자가 지켜야 할 사항, 생활습관 조정, 주의해야 할 합병증, 의료진에 알려야 하는 상황]  \n",
    "\n",
    "    - **기타:** [환자의 질문과 답변, 기타 중요한 설명, 통증, 기저질환, 회복기간, 흉터에 대한 설명]  \n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant specialized in summarizing medical conversations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    return summary\n",
    "\n",
    "def upload_summary_to_blob(summary_text, original_filename):\n",
    "    \"\"\"요약된 텍스트를 Blob Storage(sum_results 컨테이너)에 저장\"\"\"\n",
    "    summary_blob_name = original_filename.replace(\".txt\", \"_summary.txt\")\n",
    "    blob_client = blob_service_client.get_blob_client(container=SUMMARIZED_RESULTS_CONTAINER, blob=summary_blob_name)\n",
    "    blob_client.upload_blob(summary_text, overwrite=True)\n",
    "    print(f\"요약된 텍스트 업로드 완료: {summary_blob_name}\")\n",
    "\n",
    "# 🔹 실행 흐름\n",
    "audio_filename = record_and_upload()\n",
    "stt_text = transcribe_audio(audio_filename)\n",
    "\n",
    "if stt_text:\n",
    "    stt_filename = upload_stt_result_to_blob(stt_text, audio_filename)\n",
    "    summarized_text = summarize_text(stt_text)\n",
    "    upload_summary_to_blob(summarized_text, stt_filename)\n",
    "\n",
    "    print(\"\\n요약된 내용:\")\n",
    "    print(summarized_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team3-git",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
