{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\components\\chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please tell me the treatment guidelines for Cancelman's disease\n",
      "korean\n",
      "Please tell me the treatment guidelines for Castleman Disease\n",
      "korean\n",
      "Please tell me if adalimumab works\n",
      "korean\n",
      "Tell me the survival rate for iMCD (infiltrative multiple myeloma of unknown etiology)\n",
      "korean\n",
      "Tell me the iMCD survival rate\n",
      "korean\n",
      "Tell me the Castleman Disease survival rate\n",
      "korean\n",
      "Is there any information about iMCD?\n",
      "korean\n",
      "Tell me the survival rate of iMCD\n",
      "korean\n",
      "Treatment guidelines?\n",
      "korean\n",
      "Could Adalimumab Be Used as a Treatment?\n",
      "korean\n",
      "Adalimumab\n",
      "korean\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from lingua import LanguageDetectorBuilder, Language\n",
    "from deep_translator import GoogleTranslator\n",
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AI_SEARCH_ENDPOINT = os.getenv(\"AI_SEARCH_ENDPOINT\")\n",
    "AI_SEARCH_SEMANTIC = os.getenv(\"AI_SEARCH_SEMANTIC\")\n",
    "AI_SEARCH_KEY = os.getenv(\"AI_SEARCH_KEY\")\n",
    "AI_SEARCH_INDEX = os.getenv(\"AI_SEARCH_INDEX\")\n",
    "\n",
    "# Initialize language detector\n",
    "detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "\n",
    "# Function to extract a limited number of message history for GPT request\n",
    "def get_history_messages(histories):\n",
    "    history_list = list()\n",
    "\n",
    "    history_length = 5  # Define maximum number of message pairs to keep\n",
    "    history_index = 0\n",
    "\n",
    "    # Iterate through the history of messages\n",
    "    for history in histories:\n",
    "        \n",
    "        if history_index >= history_length:\n",
    "            break\n",
    "        # Separate user and assistant messages\n",
    "        message1 = history[0]\n",
    "        message2 = history[1]\n",
    "        \n",
    "        # Add the messages to the list in a structured format\n",
    "        history_list.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message1\n",
    "        })\n",
    "        history_list.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message2               \n",
    "        })\n",
    "        \n",
    "        history_index += 1\n",
    "        \n",
    "    return history_list\n",
    "\n",
    "# Function to request GPT for a response\n",
    "def request_gpt(prompt, history_list, detected_lan):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": AZURE_OPENAI_API_KEY}\n",
    "    message_list = list()\n",
    "    print(prompt)\n",
    "    print(detected_lan)\n",
    "    \n",
    "    # System role message to instruct GPT\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are an assistant for medical professionals.Always answer in {detected_lan}. If you cannot, switch to English. When asked about a disease, search the 'disease' section of the provided data. If found, answer based on the document.\"\n",
    "    })\n",
    "    # Add message history to the payload\n",
    "    message_list.extend(history_list)\n",
    "    # Add the user prompt to the payload\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\":prompt\n",
    "    })\n",
    "    # Define the payload with GPT settings and Azure Search configuration\n",
    "    payload = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.6,\n",
    "        \"max_tokens\": 800,\n",
    "        \"data_sources\": [\n",
    "        {\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": AI_SEARCH_ENDPOINT,\n",
    "                \"semantic_configuration\": AI_SEARCH_SEMANTIC,\n",
    "                \"query_type\": \"semantic\",\n",
    "                \"strictness\": 5,\n",
    "                \"top_n_documents\": 5,\n",
    "                \"key\": AI_SEARCH_KEY,\n",
    "                \"indexName\": AI_SEARCH_INDEX\n",
    "            }\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(AZURE_OPENAI_ENDPOINT, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        if content == \"The requested information is not available in the retrieved data. Please try another query or topic.\":\n",
    "            return content, None\n",
    "        # Check if there are any citations in the response\n",
    "        if response_json[\"choices\"][0][\"message\"][\"context\"]:\n",
    "            citations = response_json[\"choices\"][0][\"message\"][\"context\"][\"citations\"]\n",
    "            formatted_citation_list = list()\n",
    "            i = 0\n",
    "            for c in citations:\n",
    "                i += 1\n",
    "                temp = f\"<details><summary>Doc{i}</summary><ul>{c['content']}</ul></details>\"\n",
    "                formatted_citation_list.append(temp)\n",
    "                \n",
    "        else:\n",
    "            formatted_citation_list = list() # No citations\n",
    "            \n",
    "        text = \"\".join(formatted_citation_list)\n",
    "      \n",
    "\n",
    "        # Extract chunk and disease values using regular expressions\n",
    "        chunk_match = re.findall(r'\"chunk\"\\s*:\\s*\"([^\"]+)\"', text)\n",
    "        disease_match = re.findall(r'\"disease\"\\s*:\\s*\"([^\"]+)\"', text)\n",
    "        source_match = re.findall(r'\"source\"\\s*:\\s*\"([^\"]+)\"', text)\n",
    "\n",
    "        citation_text = []\n",
    "\n",
    "        for idx, (chunk, disease, source) in enumerate(zip(chunk_match, disease_match, source_match), start=1):\n",
    "            # Set it to expand when clicked\n",
    "            citation_t = f\"\"\"\n",
    "            <details>\n",
    "                <summary>Doc{idx}</summary>\n",
    "                <h3>Original Text</h3>\n",
    "                <span>{chunk}</span> \n",
    "                <h3>Data Sources</h3>\n",
    "                <span><b>disease</b>: {disease}, <b>source</b>: {source}</span>                \n",
    "                </details>\n",
    "                <br>\n",
    "            \"\"\"\n",
    "\n",
    "            citation_text.append(citation_t)\n",
    "\n",
    "        citation_html = \"\\n\".join(citation_text)\n",
    "\n",
    "        return content, citation_html\n",
    "\n",
    "\n",
    "    else:\n",
    "        return f\"{response.status_code}, {response.text}\", \"\"\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"Detect the language of a given text\"\"\"\n",
    "    if re.search(r\"[가-힣]\", text):\n",
    "        return \"korean\"  # If Korean characters are included, always return 'korean'   \n",
    "    detected_language = detector.detect_language_of(text)    \n",
    "    if detected_language is not None:\n",
    "        return detected_language.name.lower()  \n",
    "    return \"unknown\"  # Return 'unknown' if detection fails\n",
    "\n",
    "def translate_to_english(text):\n",
    "    \"\"\"Translate user input to english using Google Translator API\"\"\"\n",
    "    try:\n",
    "        translator = GoogleTranslator(source='auto', target='en')\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text  # Return the original text if translation fails\n",
    "\n",
    "\n",
    "# Function to handle user prompt submission\n",
    "def click_send(prompt, histories):\n",
    "    # Retrieve message history for the GPT request\n",
    "    history_list = get_history_messages(histories=histories)\n",
    "    detected_lan = detect_language(prompt)\n",
    "    trans_prompt = translate_to_english(prompt)\n",
    "    # Send the prompt and history to GPT and get the response\n",
    "    response_text, citation_html = request_gpt(trans_prompt, history_list, detected_lan)\n",
    "    histories.append((prompt, response_text))\n",
    "    return histories, \"\", citation_html\n",
    "\n",
    "\n",
    "\n",
    "### Web UI ###\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    # Main Interaction Area\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):   \n",
    "            # Chatbot, Citation area\n",
    "            with gr.Row(elem_id=\"chatbot-container\"):\n",
    "                chatbot = gr.Chatbot(label=\"Chat history\", elem_classes=\"chatbot\", height=600)\n",
    "                citation = gr.HTML(label=\"reference area\", elem_classes=\"citation-box\")\n",
    "            # Input Box and Submit Button\n",
    "            with gr.Row(elem_id=\"input-container\"):\n",
    "                input_openai_textbox = gr.Textbox(label=\"\", elem_id=\"textbox\", scale=7, placeholder=\"질문을 입력하세요...\")\n",
    "                send_button = gr.Button(\"Submit\", elem_id=\"button\", scale=1)\n",
    "            \n",
    "            # Connect the chatbot and button functionality\n",
    "            input_openai_textbox.submit(fn=click_send, inputs=[input_openai_textbox, chatbot], outputs=[chatbot, input_openai_textbox, citation])\n",
    "            send_button.click(fn=click_send, inputs=[input_openai_textbox, chatbot], outputs=[chatbot, input_openai_textbox, citation])\n",
    "\n",
    "        \n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
