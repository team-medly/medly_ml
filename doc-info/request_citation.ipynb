{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\components\\chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load environment variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AI_SEARCH_ENDPOINT = os.getenv(\"AI_SEARCH_ENDPOINT\")\n",
    "AI_SEARCH_SEMANTIC = os.getenv(\"AI_SEARCH_SEMANTIC\")\n",
    "AI_SEARCH_KEY = os.getenv(\"AI_SEARCH_KEY\")\n",
    "AI_SEARCH_INDEX = os.getenv(\"AI_SEARCH_INDEX\")\n",
    "\n",
    "# Function to extract a limited number of message history for GPT request\n",
    "def get_history_messages(histories):\n",
    "    history_list = list()\n",
    "\n",
    "    history_length = 5  # Define maximum number of message pairs to keep\n",
    "    history_index = 0\n",
    "\n",
    "    # Iterate through the history of messages\n",
    "    for history in histories:\n",
    "        \n",
    "        if history_index >= history_length:\n",
    "            break\n",
    "        # Separate user and assistant messages\n",
    "        message1 = history[0]\n",
    "        message2 = history[1]\n",
    "        \n",
    "        # Add the messages to the list in a structured format\n",
    "        history_list.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message1\n",
    "        })\n",
    "        history_list.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message2               \n",
    "        })\n",
    "        \n",
    "        history_index += 1\n",
    "        \n",
    "    return history_list\n",
    "\n",
    "# Function to request GPT for a response\n",
    "def request_gpt(prompt, history_list):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": AZURE_OPENAI_API_KEY}\n",
    "    message_list = list()\n",
    "    \n",
    "    # System role message to instruct GPT\n",
    "    message_list.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"\n",
    "                    You are an assistant for medical professionals. \n",
    "                    When asked about a disease, search the \"disease\" section of the provided data. If found, answer based on the document. \n",
    "                    If not, inform the user that no document is available for that disease.\n",
    "                \"\"\"\n",
    "    })\n",
    "    # Add message history to the payload\n",
    "    message_list.extend(history_list)\n",
    "    # Add the user prompt to the payload\n",
    "    message_list.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\":prompt\n",
    "    })\n",
    "    # Define the payload with GPT settings and Azure Search configuration\n",
    "    payload = {\n",
    "        \"messages\": message_list,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.6,\n",
    "        \"max_tokens\": 800,\n",
    "        \"data_sources\": [\n",
    "        {\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": AI_SEARCH_ENDPOINT,\n",
    "                \"semantic_configuration\": AI_SEARCH_SEMANTIC,\n",
    "                \"query_type\": \"semantic\",\n",
    "                \"strictness\": 5,\n",
    "                \"top_n_documents\": 5,\n",
    "                \"key\": AI_SEARCH_KEY,\n",
    "                \"indexName\": AI_SEARCH_INDEX\n",
    "            }\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(AZURE_OPENAI_ENDPOINT, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        if content == \"The requested information is not available in the retrieved data. Please try another query or topic.\":\n",
    "            return content, None\n",
    "        # Check if there are any citations in the response\n",
    "        if response_json[\"choices\"][0][\"message\"][\"context\"]:\n",
    "            citations = response_json[\"choices\"][0][\"message\"][\"context\"][\"citations\"]\n",
    "            formatted_citation_list = list()\n",
    "            i = 0\n",
    "            for c in citations:\n",
    "                i += 1\n",
    "                temp = f\"<details><summary>Doc{i}</summary><ul>{c['content']}</ul></details>\"\n",
    "                formatted_citation_list.append(temp)\n",
    "                \n",
    "        else:\n",
    "            formatted_citation_list = list() # No citations\n",
    "            \n",
    "        return content, \"\".join(formatted_citation_list) # Return response content and formatted citations\n",
    "    else:\n",
    "        return f\"{response.status_code}, {response.text}\", \"\"\n",
    "\n",
    "# Function to handle user prompt submission\n",
    "def click_send(prompt, histories):\n",
    "    # Retrieve message history for the GPT request\n",
    "    history_list = get_history_messages(histories=histories)\n",
    "    # Send the prompt and history to GPT and get the response\n",
    "    response_text, citation_html = request_gpt(prompt, history_list)\n",
    "    histories.append((prompt, response_text))\n",
    "    return histories, \"\", citation_html\n",
    "\n",
    "\n",
    "\n",
    "### Web UI ###\n",
    "with gr.Blocks(css=\"styles.css\") as demo:\n",
    "    \n",
    "    # Main Interaction Area\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):   \n",
    "            # Chatbot, Citation area\n",
    "            with gr.Row(elem_id=\"chatbot-container\"):\n",
    "                chatbot = gr.Chatbot(label=\"Chat history\", elem_classes=\"chatbot\")\n",
    "                citation = gr.HTML(label=\"reference area\", elem_classes=\"citation-box\")\n",
    "            # Input Box and Submit Button\n",
    "            with gr.Row(elem_id=\"input-container\"):\n",
    "                input_openai_textbox = gr.Textbox(label=\"\", elem_id=\"textbox\", scale=7, placeholder=\"질문을 입력하세요...\")\n",
    "                send_button = gr.Button(\"Submit\", elem_id=\"button\", scale=1)\n",
    "            \n",
    "            # Connect the chatbot and button functionality\n",
    "            input_openai_textbox.submit(fn=click_send, inputs=[input_openai_textbox, chatbot], outputs=[chatbot, input_openai_textbox, citation])\n",
    "            send_button.click(fn=click_send, inputs=[input_openai_textbox, chatbot], outputs=[chatbot, input_openai_textbox, citation])\n",
    "\n",
    "        \n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
